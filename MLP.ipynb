{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2\n",
    "\n",
    "#### Marcos Cesar Ribeiro de Camargo - 9278045\n",
    "#### Rafael Augusto Monteiro - 9293095\n",
    "\n",
    "###### Atenção: Esse código requer Python 3.6 por usar f-strings nos prints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Usado para aritmética de arrays da MLP\n",
    "import pandas as pd # Usado para operações com os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    model = None\n",
    "\n",
    "    @staticmethod\n",
    "    def f(net):\n",
    "        return ( 1/ (1+ np.exp(-net)) )\n",
    "\n",
    "    @staticmethod\n",
    "    def df_dnet(f_net):\n",
    "        return ( f_net * (1 - f_net) )\n",
    "\n",
    "    def __init__(self, input_length=2, hidden_length=[3, 3], output_length=1, activation_function=f , d_activation_function=df_dnet):\n",
    "        hidden_layer = list()\n",
    "        previous_length = input_length\n",
    "        for layer_length in hidden_length:\n",
    "            hidden_layer.append(np.random.rand(layer_length, previous_length+1) - 0.5)\n",
    "            previous_length = layer_length\n",
    "\n",
    "        self.model = {\n",
    "            'input_length': input_length, \n",
    "            'hidden_length': hidden_length, \n",
    "            'output_length': output_length, \n",
    "            'activation_function': activation_function.__func__, \n",
    "            'd_activation_function': d_activation_function.__func__,\n",
    "            'hidden': hidden_layer,\n",
    "            'output': (np.random.rand(output_length, previous_length+1) - 0.5),\n",
    "        }\n",
    "\n",
    "    # Função de classificação/regressão sobre um item\n",
    "    def forward(self, x):\n",
    "        # Recuperando valores do modelo\n",
    "        hidden = self.model['hidden']\n",
    "        hidden_length = len(self.model['hidden_length'])\n",
    "        output = self.model['output']\n",
    "        f = self.model['activation_function']\n",
    "        df = self.model['d_activation_function']\n",
    "\n",
    "        # Camadas Escondidas\n",
    "        net_h = [None] * hidden_length\n",
    "        f_net_h = [None] * hidden_length\n",
    "        df_net_h = [None] * hidden_length\n",
    "        \n",
    "        \n",
    "        # Adicionando 1 para multiplicar o Theta.\n",
    "        previous_layer = np.pad(x, (0, 1), 'constant', constant_values=(1))\n",
    "        for i in range(hidden_length):\n",
    "            net_h[i] = np.sum(np.multiply(hidden[i], previous_layer), axis=1)\n",
    "            f_net_h[i] = f(net_h[i])\n",
    "            df_net_h[i] = df(f_net_h[i])\n",
    "            previous_layer = np.pad(f_net_h[i], (0, 1), 'constant', constant_values=(1))\n",
    "\n",
    "            \n",
    "        # Camada de Saída\n",
    "        net_o = np.sum(np.multiply(output, previous_layer), axis=1)\n",
    "        f_net_o = f(net_o)\n",
    "        df_net_o = df(f_net_o)\n",
    "\n",
    "        # Retornando valores do forward.\n",
    "        return {\n",
    "            'net_h': net_h,\n",
    "            'f_net_h': f_net_h,\n",
    "            'df_net_h': df_net_h,\n",
    "            'net_o': net_o,\n",
    "            'f_net_o': f_net_o,\n",
    "            'df_net_o': df_net_o,\n",
    "        }\n",
    "\n",
    "    # Função de treino da MLP\n",
    "    def backpropagation(self, X, Y, eta=0.1, threshold=1e-3, alpha=0,max_inter = 200000):\n",
    "        squaredError = 2*threshold\n",
    "        hidden_length = len(self.model['hidden_length'])\n",
    "        counter = 0\n",
    "        \n",
    "        dE2_dw_o_t = 0\n",
    "        dE2_dw_h_t = [0] * hidden_length\n",
    "        while(squaredError > threshold and counter < max_inter):\n",
    "            squaredError = 0\n",
    "            # Pra cada valor do conjunto de dados\n",
    "            for x, y in zip(X, Y):\n",
    "                # Calculando saída\n",
    "                results = self.forward(x)\n",
    "                #  Calculando o erro\n",
    "                error = (y - results['f_net_o'])                \n",
    "                squaredError += np.sum(np.power(error, 2))\n",
    "                \n",
    "\n",
    "                # Backwards camada de saída\n",
    "                h = hidden_length - 1\n",
    "                delta_o = error * results['df_net_o']\n",
    "                f_net_h = np.pad(results['f_net_h'][h], (0, 1), 'constant', constant_values=(1))\n",
    "                dE2_dw_o = np.multiply(np.array([-2*delta_o]).T, np.array([f_net_h]))\n",
    "                \n",
    "                # Backwards camada escondida\n",
    "                delta_h = [None] * hidden_length\n",
    "                dE2_dw_h = [None] * hidden_length\n",
    "                delta = delta_o\n",
    "                w_o_kj = self.model['output'][:,0:self.model['hidden_length'][h]] \n",
    "\n",
    "                # For reverso\n",
    "                for i in reversed(range(1, hidden_length)):\n",
    "                    # Cálculo das adaptações\n",
    "                    delta_h[i] = np.array([results['df_net_h'][i]]) * np.dot(delta, w_o_kj)         \n",
    "                    dE2_dw_h[i] = np.multiply(-2*delta_h[i].T,\n",
    "                        np.pad(results['f_net_h'][i-1], (0, 1), 'constant', constant_values=(1)))\n",
    "                    # Controlando as iterações\n",
    "                    delta = delta_h[i]\n",
    "                    w_o_kj = self.model['hidden'][i][:, 0:self.model['hidden_length'][i-1]]\n",
    "                    \n",
    "                delta_h[0] = np.array([results['df_net_h'][0]]) * np.dot(delta, w_o_kj)               \n",
    "                dE2_dw_h[0] =  np.multiply(-2*delta_h[0].T,\n",
    "                    np.pad(x, (0, 1), 'constant', constant_values=(1)))\n",
    "                               \n",
    "                \n",
    "                # Aplicar adaptação na saída\n",
    "                self.model['output'] = self.model['output'] - eta * dE2_dw_o - alpha*dE2_dw_o_t\n",
    "\n",
    "                # Aplicar adaptação na escondida\n",
    "                for i in range(hidden_length):\n",
    "                    self.model['hidden'][i] = self.model['hidden'][i] - eta * dE2_dw_h[i] - alpha*dE2_dw_h_t[i]\n",
    "\n",
    "                dE2_dw_o_t = dE2_dw_o\n",
    "                dE2_dw_h_t = dE2_dw_h\n",
    "                \n",
    "            squaredError = squaredError / len(X) \n",
    "            counter += 1\n",
    "            if(counter % 100 == 0):\n",
    "                print('currently with error %.6lf - on iter. %d' % (squaredError, counter))\n",
    "        print(f'error {squaredError:.6f} - iter. {counter}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções abaixo servem para operações auxiliares sobre os datasets e sobre os resultados da MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Funções Auxiliares #########\n",
    "\n",
    "# Função de normalização chamada para cada coluna\n",
    "def norm_f(col):\n",
    "    return (col - col.min()) / (col.max() - col.min())\n",
    "\n",
    "# Função para normalizar um dataframe no intervalo [0,1]\n",
    "def normalize_df(df):\n",
    "    return df.apply(norm_f, axis=0)\n",
    "\n",
    "# Função para realizar o split do dataset em treino e teste\n",
    "def split_dataset(df, split_percentage):\n",
    "    train_size = int(df.shape[0] * 0.8) # dataset de treino: 80% do total\n",
    "    train = df.iloc[:train_size,:]\n",
    "    test = df.iloc[train_size:,:]\n",
    "    return (train, test)\n",
    "\n",
    "# Função para classificar um conjunto de dados inteiro. \n",
    "def batch_classify(classifier, data, discretize = True):\n",
    "    if discretize: # se eu precisar trocar os valores reais por binarios (caso wine)\n",
    "        result = []\n",
    "        for instance in data:\n",
    "            predict = classifier.forward(instance)['f_net_o']\n",
    "            result.append(np.where(predict == predict.max(),1,0))\n",
    "        return np.array(result)\n",
    "    else: # se eu nao precisar trocar nada, posso soh usar list comprehension\n",
    "        return np.array([classifier.forward(instance)['f_net_o'] for instance in data])\n",
    "\n",
    "# Função para transformar uma lista de listas de variáveis dummies em uma lista de classes\n",
    "def undummy(y):\n",
    "    result = []\n",
    "    for item in y:\n",
    "        if item[0] == 1:\n",
    "            result.append(1)\n",
    "        elif item[1] == 1:\n",
    "            result.append(2)\n",
    "        elif item[2] == 1:\n",
    "            result.append(3)\n",
    "    return result\n",
    "\n",
    "# Função para calcular acurácia média dado uma lista de predições e uma lista de classes reais\n",
    "def accuracy(y_true, y_pred):\n",
    "    score = 0;\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            score += 1\n",
    "    return score/len(y_true)\n",
    "\n",
    "# Função para calcular erro médio quadrático\n",
    "def mse(y_true, y_pred):\n",
    "    return (np.sum((y_pred - y_true) ** 2)) / (y_pred.shape[0] * y_pred.shape[1])\n",
    "\n",
    "# Função para printar o resultado dos testes de maneira mais bonita\n",
    "def print_results(result):  \n",
    "    print(f'Test dataset Accuracy: {result[\"test\"]:.0%}  //  Train dataset Accuracy: {result[\"train\"]:.0%}')\n",
    "    \n",
    "# Função para printar o resultado dos MSE de maneira mais bonita\n",
    "def print_results_mse(result):  \n",
    "    print(f'Test dataset Mean Squared Error: {result[\"test\"]:.3f}  //  Train dataset Mean Squared Error: {result[\"train\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função abaixo realiza todos os passos para a avaliação da MLP sobre o dataset wine, com excessão da leitura do arquivo. Primeiro, é feita a substituição da classe (1, 2 ou 3) por variáveis dummies (são criados atributos 1, 2 e 3, e cada instância possui 0 ou 1 em cada atributo conforme a sua classe). \n",
    "\n",
    "Em seguida, as instâncias do dataset são aleatorizadas. \n",
    "\n",
    "No próximo passo, todos os campos do dataset são normalizados em 0-1. \n",
    "\n",
    "Então, o dataset é dividido em treino e teste, de acordo com o parâmetro *train_percentage*. \n",
    "\n",
    "Em seguida, as classes e os dados são separados. \n",
    "\n",
    "Finalmente, é realizado o treino da MLP, com os parâmetros:\n",
    "* *layers*: formato das camadas ocultas. Uma camada com 10 neurônios por default\n",
    "* *max_cycles*: número máximo de iterações do treinamento. 20k por default\n",
    "* *momentum*: valor do foward momentum. 0.3 por default\n",
    "* *eta*: taxa de aprendizado. 0.1 por default\n",
    "\n",
    "Em seguida, é realizado o *batch_classify*, classificando todas as instâncias dos conjuntos de treino e teste. Tais classificações passam pelo *undummy* (As classes são convertidas novamente a 1,2 ou 3). \n",
    "\n",
    "Por fim, é feito o cálculo da acurácia das classificações no conjunto de treinamento e teste, e o resultado é retornado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que realiza todos os procedimentos para o teste da MLP conforme as especificações do trabalho\n",
    "def classification_test_wine(dataset, layers = [10], max_cycles = 20000, momentum = 0.3, eta = 0.1, train_percentage = 0.8):\n",
    "\n",
    "    # Substituindo classes por variáveis dummies\n",
    "    df = pd.concat([pd.get_dummies(dataset['Class']), dataset.iloc[:,1:]], axis=1)\n",
    "    \n",
    "    # Aleatorizando as entradas\n",
    "    df = df.sample(frac=1)\n",
    "    \n",
    "    # Normalizando as colunas para o intervalo [0, 1]\n",
    "    df = normalize_df(df)\n",
    "    \n",
    "    # Dividindo o dataset dataset\n",
    "    train, test = split_dataset(df, train_percentage)\n",
    "    \n",
    "    # Separando classes dos datasets\n",
    "    train_target = train.iloc[:,:3].values\n",
    "    train_data = train.drop(columns=[1,2,3]).values\n",
    "    test_target = test.iloc[:,:3].values\n",
    "    test_data = test.drop(columns=[1,2,3]).values\n",
    "    \n",
    "    # Treinando a mlp\n",
    "    mlp = MLP(input_length = train_data.shape[1], hidden_length=layers, output_length = train_target.shape[1])\n",
    "    mlp.backpropagation(train_data, train_target, alpha=momentum, threshold=1e-3, max_inter=max_cycles)\n",
    "    \n",
    "    # Realizando os testes\n",
    "    test_predict = undummy(batch_classify(mlp, test_data))\n",
    "    test_target = undummy(test_target)\n",
    "    train_predict = undummy(batch_classify(mlp, train_data))\n",
    "    train_target = undummy(train_target)\n",
    "\n",
    "    return {'test': accuracy(test_target, test_predict), 'train': accuracy(train_target, train_predict)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplos\n",
    "\n",
    "No código abaixo, o dataset Wine é carregado e alguns testes são realizados com diversos parâmetros diferentes. Para cada execução, são mostrados o número de iterações do treinamento, o erro do treinamento, e a acurácia nos conjuntos de teste e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers: 1, train %: 50%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.011454 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.016734 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.009860 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.017857 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.018426 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.018231 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.013854 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.019255 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.014222 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.1, momentum:  0.1,  max_iter: 50\n",
      "error 0.018317 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.016780 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.018874 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.016917 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.017588 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.014575 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.016299 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.017100 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.016132 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.019994 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.2, momentum:  0.1,  max_iter: 50\n",
      "error 0.012093 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.016673 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.015378 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.018986 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.013227 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.018761 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.011276 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.017248 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.020310 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.017689 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.3, momentum:  0.1,  max_iter: 50\n",
      "error 0.011725 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.019847 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.019562 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.012591 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.013598 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.017855 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.016224 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.021135 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.018377 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.015724 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.4, momentum:  0.1,  max_iter: 50\n",
      "error 0.008620 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.013401 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.007098 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.014488 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.004898 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.014949 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.007414 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.014968 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.006412 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.012146 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.1, momentum:  0.2,  max_iter: 50\n",
      "error 0.011436 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.2, momentum:  0.2,  max_iter: 50\n",
      "error 0.014132 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.2, momentum:  0.2,  max_iter: 50\n",
      "error 0.010950 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.2, momentum:  0.2,  max_iter: 50\n",
      "error 0.006099 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.2, momentum:  0.2,  max_iter: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0.008751 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.2, momentum:  0.2,  max_iter: 50\n",
      "error 0.013215 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.2, momentum:  0.2,  max_iter: 50\n",
      "error 0.006164 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.2, momentum:  0.2,  max_iter: 50\n",
      "error 0.009091 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.2, momentum:  0.2,  max_iter: 50\n",
      "error 0.010986 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.2, momentum:  0.2,  max_iter: 50\n",
      "error 0.015189 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.2, momentum:  0.2,  max_iter: 50\n",
      "error 0.005334 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.013453 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.006936 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.009553 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.005707 - iter. 50\n",
      "Test dataset Accuracy: 92%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.009206 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.006556 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.009125 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.012492 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.006927 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.3, momentum:  0.2,  max_iter: 50\n",
      "error 0.013500 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.007336 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.011615 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.013644 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.011972 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.012803 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.007053 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.011887 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.012786 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.013523 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.4, momentum:  0.2,  max_iter: 50\n",
      "error 0.006466 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.007847 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.006012 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.004118 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.003629 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.007029 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.007682 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.011873 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.004214 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.006262 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.1, momentum:  0.3,  max_iter: 50\n",
      "error 0.005972 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.003931 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.004810 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.006592 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.010347 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.007374 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.004008 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.008684 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.011812 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.010072 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.2, momentum:  0.3,  max_iter: 50\n",
      "error 0.008174 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.3, momentum:  0.3,  max_iter: 50\n",
      "error 0.008703 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.3, momentum:  0.3,  max_iter: 50\n",
      "error 0.010443 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.3, momentum:  0.3,  max_iter: 50\n",
      "error 0.009948 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.3, momentum:  0.3,  max_iter: 50\n",
      "error 0.012406 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.3, momentum:  0.3,  max_iter: 50\n",
      "error 0.005504 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.3, momentum:  0.3,  max_iter: 50\n",
      "error 0.007467 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.3, momentum:  0.3,  max_iter: 50\n",
      "error 0.008339 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.3, momentum:  0.3,  max_iter: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0.003829 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.3, momentum:  0.3,  max_iter: 50\n",
      "error 0.010938 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.3, momentum:  0.3,  max_iter: 50\n",
      "error 0.008553 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.005105 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.012328 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.004499 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.007711 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.009696 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.008665 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.004811 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.004421 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.007234 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.4, momentum:  0.3,  max_iter: 50\n",
      "error 0.005019 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.007445 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.005061 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.004900 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.005901 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.006401 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.004216 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.002429 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.006237 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.005592 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.1, momentum:  0.4,  max_iter: 50\n",
      "error 0.009014 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.004198 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.005732 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.003252 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.005771 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.009090 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.004179 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.006906 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.004137 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.006020 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.2, momentum:  0.4,  max_iter: 50\n",
      "error 0.005867 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.009953 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.005033 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.003230 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.006668 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.003814 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.007078 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.002812 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.006222 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.003784 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.3, momentum:  0.4,  max_iter: 50\n",
      "error 0.004356 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.004840 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.004799 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.003519 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.003312 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.003332 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.003269 - iter. 50\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.002939 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.006336 - iter. 50\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 99%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.003571 - iter. 50\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.4, momentum:  0.4,  max_iter: 50\n",
      "error 0.004585 - iter. 50\n",
      "Test dataset Accuracy: 89%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.1, momentum:  0.1,  max_iter: 100\n",
      "error 0.005432 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.1, momentum:  0.1,  max_iter: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0.008328 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.1, momentum:  0.1,  max_iter: 100\n",
      "error 0.010087 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.1, momentum:  0.1,  max_iter: 100\n",
      "error 0.004775 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.1, momentum:  0.1,  max_iter: 100\n",
      "error 0.004389 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.1, momentum:  0.1,  max_iter: 100\n",
      "error 0.006437 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.1, momentum:  0.1,  max_iter: 100\n",
      "error 0.007615 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.1, momentum:  0.1,  max_iter: 100\n",
      "error 0.005272 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.1, momentum:  0.1,  max_iter: 100\n",
      "error 0.009252 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.1, momentum:  0.1,  max_iter: 100\n",
      "error 0.006918 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.006348 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.003349 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.006690 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.009310 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.005611 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.003998 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.006025 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.007132 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.008272 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.2, momentum:  0.1,  max_iter: 100\n",
      "error 0.003473 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.006200 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.002881 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.005858 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.004839 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.008195 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.005449 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.007913 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.008376 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.004187 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.3, momentum:  0.1,  max_iter: 100\n",
      "error 0.005654 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.004046 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.010353 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.006279 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.006464 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.006345 - iter. 100\n",
      "Test dataset Accuracy: 86%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.008238 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.006697 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.003654 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.005961 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.4, momentum:  0.1,  max_iter: 100\n",
      "error 0.006510 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.001957 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.002381 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.004926 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.002587 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.002943 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.004334 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.002906 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.003911 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.003906 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.1, momentum:  0.2,  max_iter: 100\n",
      "error 0.004119 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.2, momentum:  0.2,  max_iter: 100\n",
      "error 0.004305 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.2, momentum:  0.2,  max_iter: 100\n",
      "error 0.004236 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.2, momentum:  0.2,  max_iter: 100\n",
      "error 0.004023 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.2, momentum:  0.2,  max_iter: 100\n",
      "error 0.003195 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.2, momentum:  0.2,  max_iter: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0.004276 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.2, momentum:  0.2,  max_iter: 100\n",
      "error 0.004691 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.2, momentum:  0.2,  max_iter: 100\n",
      "error 0.002193 - iter. 100\n",
      "Test dataset Accuracy: 92%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.2, momentum:  0.2,  max_iter: 100\n",
      "error 0.004174 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.2, momentum:  0.2,  max_iter: 100\n",
      "error 0.003753 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.2, momentum:  0.2,  max_iter: 100\n",
      "error 0.003921 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.002749 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.005630 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.004143 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.006834 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.004802 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.003749 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.002396 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.003335 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.002390 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.3, momentum:  0.2,  max_iter: 100\n",
      "error 0.003987 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.002094 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.004927 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.007018 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.005217 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.003815 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.005864 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.002325 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.004632 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.003347 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.4, momentum:  0.2,  max_iter: 100\n",
      "error 0.004803 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.002846 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.001393 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.001901 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.002526 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.002222 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.002645 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.001480 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.002033 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.001332 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.1, momentum:  0.3,  max_iter: 100\n",
      "error 0.001504 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.001807 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.003417 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.001451 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.003015 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.001188 - iter. 100\n",
      "Test dataset Accuracy: 92%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.001913 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.002518 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.003296 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.002588 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.2, momentum:  0.3,  max_iter: 100\n",
      "error 0.002704 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.3, momentum:  0.3,  max_iter: 100\n",
      "error 0.002549 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.3, momentum:  0.3,  max_iter: 100\n",
      "error 0.002380 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.3, momentum:  0.3,  max_iter: 100\n",
      "error 0.005266 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.3, momentum:  0.3,  max_iter: 100\n",
      "error 0.001663 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.3, momentum:  0.3,  max_iter: 100\n",
      "error 0.002535 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.3, momentum:  0.3,  max_iter: 100\n",
      "error 0.003190 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.3, momentum:  0.3,  max_iter: 100\n",
      "error 0.003212 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.3, momentum:  0.3,  max_iter: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 0.001674 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.3, momentum:  0.3,  max_iter: 100\n",
      "error 0.002266 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.3, momentum:  0.3,  max_iter: 100\n",
      "error 0.001998 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.001509 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.002270 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.002005 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.002222 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.001677 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.001770 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.002089 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.002620 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.001833 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.4, momentum:  0.3,  max_iter: 100\n",
      "error 0.002552 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.000991 - iter. 96\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.002139 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.001055 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.001489 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.001587 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.001098 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.000992 - iter. 99\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.002265 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.002084 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.1, momentum:  0.4,  max_iter: 100\n",
      "error 0.001431 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.001669 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.001729 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.001317 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.001901 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.001551 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 70%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.001594 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 80%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.001071 - iter. 100\n",
      "Test dataset Accuracy: 92%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 80%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.002811 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 90%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.001450 - iter. 100\n",
      "Test dataset Accuracy: 97%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 90%, eta:  0.2, momentum:  0.4,  max_iter: 100\n",
      "error 0.001250 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 50%, eta:  0.3, momentum:  0.4,  max_iter: 100\n",
      "error 0.001590 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 50%, eta:  0.3, momentum:  0.4,  max_iter: 100\n",
      "error 0.001868 - iter. 100\n",
      "Test dataset Accuracy: 100%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 60%, eta:  0.3, momentum:  0.4,  max_iter: 100\n",
      "error 0.001147 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 2, train %: 60%, eta:  0.3, momentum:  0.4,  max_iter: 100\n",
      "error 0.001232 - iter. 100\n",
      "Test dataset Accuracy: 94%  //  Train dataset Accuracy: 100%\n",
      "\n",
      "layers: 1, train %: 70%, eta:  0.3, momentum:  0.4,  max_iter: 100\n"
     ]
    }
   ],
   "source": [
    "# Carregando o dataset\n",
    "wine = pd.read_csv('wine.csv', header=None ,names=['Class','Alcohol','Acid','Ash','Alca','Magnesium','TotalPhe','Flavanoids','Nonflavanoid','Proantho','CIntensity','Hue','Diluted','Proline'])\n",
    "\n",
    "for max_iter in range(50,201,50): #checks from 50 to 200\n",
    "    for momentum in [x * .1 for x in range(1, 5, 1)]: # checks from .1 to .4\n",
    "        for eta in [x * .1 for x in range(1, 5, 1)]: # checks from .1 to .4\n",
    "            for train_percentage in [x * .1 for x in range(5, 10, 1)]: # checks from .5 to .9\n",
    "                for l in range(1,3,1): # checks from 1 layer to 2 layers\n",
    "                    print(f'layers: {l}, train %: {train_percentage:.0%}, eta: {eta: .1f}, momentum: {momentum: .1f},  max_iter: {max_iter}')\n",
    "                    result = classification_test_wine(wine, max_cycles = max_iter, momentum = momentum, eta = eta, train_percentage = train_percentage)\n",
    "                    print_results(result)\n",
    "                    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: default_features_1059_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar, a função abaixo realiza todos os passos para a avaliação do dataset default_features_1059_tracks. As diferenças da função do dataset Wine é que não é necessário o uso de variáveis dummy, e o resultado calculado é o erro quadrático médio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que realiza todos os procedimentos para o teste da MLP conforme as especificações do trabalho\n",
    "def classification_test_tracks(dataset, layers = [10], max_cycles = 500, momentum = 0.3, eta = 0.1, train_percentage = 0.8,  threshold=1e-3):\n",
    "    \n",
    "    # Aleatorizando as entradas\n",
    "    df = dataset.sample(frac=1)\n",
    "    \n",
    "    # Normalizando as colunas para o intervalo [0, 1]\n",
    "    df = normalize_df(df)\n",
    "    \n",
    "    # Dividindo o dataset dataset\n",
    "    train, test = split_dataset(df, train_percentage)\n",
    "    \n",
    "    # Separando classes dos datasets\n",
    "    train_target = train.iloc[:,68:].values # pega colunas 69 e 70\n",
    "    train_data = train.drop(columns=[69,70]).values # pega colunas de 1 a 68\n",
    "    test_target = test.iloc[:,68:].values\n",
    "    test_data = test.drop(columns=[69,70]).values\n",
    "    \n",
    "    # Treinando a mlp\n",
    "    mlp = MLP(input_length = train_data.shape[1], hidden_length=layers, output_length = train_target.shape[1])\n",
    "    print('treinando mlp')\n",
    "    mlp.backpropagation(train_data, train_target, alpha=momentum, threshold=threshold, max_inter=max_cycles)\n",
    "    \n",
    "    # Realizando os testes\n",
    "    test_predict = batch_classify(mlp, test_data, discretize = False)\n",
    "    test_target = test_target\n",
    "    train_predict = batch_classify(mlp, train_data, discretize = False)\n",
    "    train_target = train_target\n",
    "    \n",
    "    return {'test': mse(test_target, test_predict), 'train': mse(train_target, train_predict)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplos\n",
    "\n",
    "No código abaixo, o dataset default_features_1059_tracks é carregado e alguns testes são realizados com diversos parâmetros diferentes. Para cada execução, são mostrados o número de iterações do treinamento, o erro do treinamento, e os erros médios quadráticos para os conjuntos de teste e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando mlp\n",
      "error 0.059120 - iter. 50\n",
      "Test dataset Mean Squared Error: 0.033  //  Train dataset Mean Squared Error: 0.029\n"
     ]
    }
   ],
   "source": [
    "# Carregando o dataset\n",
    "tracks = pd.read_csv('default_features_1059_tracks.csv', header=None ,names=range(1,71))\n",
    "\n",
    "result = classification_test_tracks(tracks, threshold=3*1e-2, eta=0.3, max_cycles=50)\n",
    "print_results_mse(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
